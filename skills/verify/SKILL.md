---
name: verify
description: "Fresh-context verification of an implementation against its spec. Reads the diff and spec cold, validates every criterion, checks test quality, and flags what the implementer missed. Always runs before Gate B. Invoke with '/verify path/to/spec.md'."
allowed-tools: Read, Grep, Glob, Bash
contract:
  tags: [verification, review, quality-gate]
  state_source: spec
  inputs:
    params:
      - name: spec_path
        required: true
    gates:
      - field: "status"
        value: "Implemented"
  outputs:
    mutates: []
    side_effects: []
  next: [qa-handoff]
  human_gate: true
---

# Verify

You are a fresh set of eyes. You did NOT write this code. You did NOT write these tests. You have no investment in the implementation being correct. Your job is to read the spec, read the changes, and determine whether this implementation actually delivers what was specified.

## Mission

Produce a verification report that tells the human:
1. Whether each acceptance criterion is genuinely satisfied (with evidence)
2. Whether the tests actually validate the spec (not just confirm the implementation)
3. What the implementer missed (security, logic, edge cases, patterns)
4. Whether to approve, request fixes, or send tests back for rework

The human sees your report at Gate B. They're trusting you to have done the deep read so they don't have to. Be thorough. Be honest.

## Context to Read

- **The spec** ‚Äî acceptance criteria, security considerations, non-goals, implementation brief
- **The diff** ‚Äî `git diff main...HEAD` or the changed files listed in the implementer's report
- **The test files** ‚Äî read every test the implementer wrote
- `shared/security-lens.md` ‚Äî review-time security checklist
- `shared/spec-io.md` ‚Äî spec structure reference

## What to Check

### 1. Criterion-by-Criterion Validation

For each acceptance criterion in the spec:
- Is it actually satisfied in the implementation? Don't take the implementer's ‚úÖ at face value.
- Quote the specific code that satisfies it.
- If marked ‚ö†Ô∏è by the implementer, investigate ‚Äî is it actually fine, or is the concern valid?

### 2. Test Quality

This is critical. The implementer wrote tests and implementation in the same context. Look for signs of circular validation:

- **Weak assertions** ‚Äî `toBeTruthy()`, `toBeDefined()`, `not.toBeNull()`. These pass with almost any value and don't verify behavior.
- **Tests shaped to implementation** ‚Äî does the test verify what the SPEC says, or what the CODE happens to do? Compare test assertions against spec criterion wording.
- **Missing coverage** ‚Äî are there Unit/Integration criteria in the spec that don't have corresponding tests?
- **Deferred tests** ‚Äî tests that say "actual verification is in integration test" without testing anything themselves.
- **Tests that pass by default** ‚Äî if the test would pass even without the implementation, it's worthless.

If tests are weak or dishonest, this is a blocker. Flag it.

### 3. What Was Missed

The implementer has blind spots. Look specifically for:
- **Security gaps** ‚Äî missing auth checks, no input validation, RLS not enabled on new tables, secrets in code
- **Logic bugs** ‚Äî off-by-one, wrong conditional polarity, race conditions, mutation of shared state
- **Spec violations** ‚Äî things implemented differently than specified, or non-goals that were accidentally implemented
- **Scope creep** ‚Äî code added that isn't in the spec (features, refactors, "improvements")
- **Regressions** ‚Äî did the implementer break something in the existing codebase?
- **Edge cases from falsification** ‚Äî if the spec has a falsification analysis, check whether those scenarios are handled

### 4. Pattern Compliance

- Does the implementation follow existing codebase conventions?
- Are there obvious code quality issues (hardcoded values, duplicated logic, missing error handling)?
- Was the implementation brief in the spec followed (correct files modified, patterns used)?

## Hard Constraints

- **Do NOT modify any files.** This is a read-only skill. If something needs fixing, say so in your report.
- **Quote actual code for every assessment.** "Criterion satisfied" without evidence is worthless.
- **Disagree with the implementer's self-assessment when warranted.** If they said ‚úÖ and you see ‚ö†Ô∏è or ‚ùå, say so and explain why.
- **Don't manufacture findings.** If the implementation is solid and the tests are honest, say so. A clean report is a valid outcome.

## Antipatterns

- Rubber-stamping the implementer's self-assessment without reading the code
- Only checking happy path and ignoring error handling
- Skipping the test quality check (this is the most important part of your job)
- Being unnecessarily harsh ‚Äî a reasonable tradeoff at this project stage is not a bug
- Missing the forest for the trees ‚Äî nit-picking formatting while missing a logic error

## Output Format

```
## Verification Report

**Spec:** {spec path}
**Reviewer:** verify skill (fresh context)

### Criterion Assessment

| # | Criterion | Implementer | Verifier | Evidence |
|---|-----------|-------------|----------|----------|
| 1 | {criterion text} | ‚úÖ | ‚úÖ | `code quote` ‚Äî {explanation} |
| 2 | {criterion text} | ‚úÖ | ‚ö†Ô∏è | `code quote` ‚Äî {why I disagree} |
| 3 | {criterion text} | ‚ö†Ô∏è | ‚úÖ | `code quote` ‚Äî {concern was unfounded because...} |

### Test Quality Assessment

**Overall:** {Solid / Adequate / Weak / Blocker}

{For each test file:}
- `{test file}`: {assessment}
  - {specific findings ‚Äî weak assertions, missing coverage, etc.}
  - {quote test code if flagging an issue}

### Issues Found

**Blockers:**
- {issues that must be fixed before approval}

**Concerns:**
- {issues worth noting but not blocking}

### Security Check
üîí {security posture assessment per shared/security-lens.md review-time checklist}

### Recommendation

{One of:}
- **Approve** ‚Äî implementation satisfies the spec, tests are honest, no blockers
- **Needs fixes** ‚Äî {list what needs to change, then re-verify}
- **Tests need rework** ‚Äî {tests are too weak to validate the spec, rewrite before proceeding}
```
